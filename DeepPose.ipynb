{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepPose.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lONv0lL2ja0A",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9bp8eSRc2Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iIJObJnC4qyL",
        "colab": {}
      },
      "source": [
        "# # Mounting Google Drive to access images\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "de7dThIrkLUh",
        "colab": {}
      },
      "source": [
        "# data_path = \"/content/drive/My Drive/lsp_dataset/images/\"\n",
        "data_path = \"./lsp_dataset/images/\"\n",
        "\n",
        "# Find max size of an image in both dimensions\n",
        "max_h, max_w = 0, 0\n",
        "for file_name in os.listdir(data_path):\n",
        "    img = plt.imread(data_path+file_name)\n",
        "    if img.shape[0] > max_h: max_h = img.shape[0]\n",
        "    if img.shape[1] > max_w: max_w = img.shape[1]\n",
        "\n",
        "print(\"max h and w are:\",max_h, max_w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ilsUv3Gf6NPf",
        "colab": {}
      },
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "joint_data = loadmat(\"./lsp_dataset/joints.mat\") #/content/drive/My Drive/lsp_dataset/joints.mat\n",
        "# joint_data[\"joints\"]\n",
        "print(\"total shape:\",joint_data[\"joints\"].shape)\n",
        "print(\"x shape:\",joint_data[\"joints\"][0].shape)\n",
        "print(\"y shape:\",joint_data[\"joints\"][1].shape)\n",
        "print(\"visibility shape:\",joint_data[\"joints\"][2].shape)\n",
        "print(\"labels for head top for a random picture:\",joint_data[\"joints\"][0][13][10],joint_data[\"joints\"][1][13][10],joint_data[\"joints\"][2][13][10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RfLrb8cCHHvf",
        "colab": {}
      },
      "source": [
        "img = \"im1325.jpg\"\n",
        "img_num = 1324\n",
        "plt.figure()\n",
        "print(data_path+img)\n",
        "img = plt.imread(data_path+img)\n",
        "print(img.shape, type(img), img.min(), img.max())\n",
        "plt.imshow(img);\n",
        "\n",
        "for i in range(14):\n",
        "    if joint_data[\"joints\"][2][i][img_num] == 0.0: c = 'b'\n",
        "    else: c = 'r'\n",
        "  \n",
        "    plt.plot(joint_data[\"joints\"][0][i][img_num],joint_data[\"joints\"][1][i][img_num],'.', color=c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gxMKSHeuB3Y_",
        "colab": {}
      },
      "source": [
        "class LSP_Dataset(Dataset):\n",
        "    def __init__(self, max_h, max_w, path=\"./lsp_dataset/\"): #/content/drive/My Drive\n",
        "    \n",
        "        self.max_h = max_h\n",
        "        self.max_w = max_w\n",
        "\n",
        "        # Load joint data from the mat file\n",
        "        self.joint_data = loadmat(path+\"joints.mat\")[\"joints\"]\n",
        "\n",
        "        # Load and store images (float) into a list\n",
        "        self.array_of_images = np.empty([2000,self.max_h,self.max_w,3],dtype=float)\n",
        "        self.array_of_labels = np.empty([2000,2,14],dtype=float)\n",
        "        for file_idx, file_name in enumerate(sorted(os.listdir(path+\"images/\"))):\n",
        "            padded_img, padded_labels      = pad_to_max(plt.imread(path+\"images/\"+file_name), \n",
        "                                                      self.joint_data[:2,:,file_idx], \n",
        "                                                      self.max_h, self.max_w)\n",
        "            self.array_of_images[file_idx] = padded_img/256.0\n",
        "            self.array_of_labels[file_idx] = padded_labels/202 - 0.5\n",
        "\n",
        "#         Normalization\n",
        "#         self.mean_img = np.mean(self.array_of_images,axis=0)\n",
        "#         self.std_img  = np.std(self.array_of_images,axis=0)\n",
        "#         self.array_of_images = (((self.array_of_images - self.mean_img)/(self.std_img+0.0001)) + 1)/2\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return self.array_of_images[idx], self.array_of_labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.array_of_images.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "def pad_to_max(img, labels, max_h, max_w):\n",
        "    img_h, img_w, _  = img.shape\n",
        "    padded_img       = np.zeros([max_h,max_w,3])\n",
        "    start_h, start_w = int((max_h-img_h)/2), int((max_w-img_w)/2)\n",
        "\n",
        "    padded_img[start_h:start_h+img.shape[0], start_w:start_w+img.shape[1], :] = img\n",
        "    padded_labels = labels + np.array([[start_w], [start_h]])\n",
        "\n",
        "    return padded_img, padded_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M_eJla2w725v",
        "colab": {}
      },
      "source": [
        "dataset = LSP_Dataset(202,202)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fyg2dSFXGXod",
        "colab": {}
      },
      "source": [
        "img_num = 123\n",
        "plt.figure()\n",
        "print(dataset.__getitem__(img_num)[0].min(),dataset.__getitem__(img_num)[0].max())\n",
        "plt.imshow(dataset.__getitem__(img_num)[0])\n",
        "plt.scatter(202*(0.5 + np.transpose(dataset.__getitem__(img_num)[1])[:,0]), 202*(0.5 + np.transpose(dataset.__getitem__(img_num)[1])[:,1]),s=8,c=\"r\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uryievJ1ubRg",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "total      = 2000\n",
        "train_size = int(total*0.6)\n",
        "val_size   = int(total*0.2)\n",
        "test_size  = total - train_size - val_size\n",
        "\n",
        "lengths    = [train_size,val_size,test_size]\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.dataset.random_split(dataset,lengths)\n",
        "\n",
        "train_dl = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "val_dl   = DataLoader(val_dataset,batch_size=batch_size,shuffle=True)\n",
        "test_dl  = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0AOUY1AhIkqF",
        "colab": {}
      },
      "source": [
        "class DeepPose(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepPose,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0)\n",
        "        self.lrn1  = nn.LocalResponseNorm(size=2, alpha=2e-05, beta=0.75, k=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=0)\n",
        "        self.lrn2  = nn.LocalResponseNorm(size=2, alpha=2e-05, beta=0.75, k=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=0)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "        self.fc1   = nn.Linear(in_features=256, out_features=4096)\n",
        "        self.fc2   = nn.Linear(in_features=4096, out_features=4096)\n",
        "        self.out   = nn.Linear(in_features=4096, out_features=28)\n",
        "\n",
        "    def forward(self,input):\n",
        "        x = input.view((input.shape[0],input.shape[3],input.shape[1],input.shape[2]))\n",
        "        x = self.pool1(self.lrn1(F.relu(self.conv1(x))))\n",
        "        x = self.pool2(self.lrn2(F.relu(self.conv2(x))))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool3(F.relu(self.conv5(x)))\n",
        "        x = torch.flatten(x,1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tMlv6Y4d8BwC",
        "colab": {}
      },
      "source": [
        "model = DeepPose().float().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bh5XLBRgLZfe",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss(reduction=\"sum\")\n",
        "optimizer = torch.optim.Adagrad(model.parameters(),lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w3-CTHqb8VW6",
        "colab": {}
      },
      "source": [
        "def train(epochs=10, model=model, train_dl=train_dl, val_dl=val_dl, optimizer=optimizer, criterion=criterion, \n",
        "          train_size=train_size, val_size=val_size):\n",
        "    \n",
        "    train_loss_lst, val_loss_lst, batch_epoch_loss_lst = [], [], []\n",
        "    \n",
        "    for e in range(epochs):\n",
        "        train_loss, val_loss = 0, 0\n",
        "        \n",
        "        # Training\n",
        "        for batch_idx,(batch_imgs,batch_labels) in enumerate(train_dl):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            batch_imgs,batch_labels = batch_imgs.float().to(device),batch_labels.to(device)\n",
        "            output = model(batch_imgs)\n",
        "            \n",
        "            # Reshape the outputs batch_size x 28 -> batch_size x 2 x 14\n",
        "            output = output.view(batch_labels.shape)\n",
        "            \n",
        "            loss = criterion(output,batch_labels.float())\n",
        "            batch_epoch_loss_lst.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        \n",
        "        train_loss_lst.append(train_loss/train_size)\n",
        "        \n",
        "        # Validation\n",
        "        for batch_idx,(batch_imgs,batch_labels) in enumerate(val_dl):\n",
        "            model.eval()\n",
        "            batch_imgs,batch_labels = batch_imgs.float().to(device),batch_labels.to(device)\n",
        "            output = model(batch_imgs)\n",
        "            \n",
        "            # Reshape the outputs batch_size x 28 -> batch_size x 2 x 14\n",
        "            output = output.view(batch_labels.shape)\n",
        "            loss = criterion(output,batch_labels.float())\n",
        "            val_loss += loss.item()\n",
        "        \n",
        "        val_loss_lst.append(val_loss/val_size)\n",
        "        \n",
        "        if e%1==0:\n",
        "            print(\"[{}/{}]: Train loss={:2.4f}, Validation loss={:2.4f}\".format(e+1,epochs,train_loss_lst[-1],val_loss_lst[-1]))\n",
        "#             for param in model.parameters():\n",
        "#                 print(param.data)\n",
        "#         print()\n",
        "\n",
        "        if train_loss_lst[-1]<=0.25:\n",
        "            for param in optimizer.param_groups:\n",
        "                param[\"lr\"]=5e-4\n",
        "                \n",
        "            if train_loss_lst[-1]<=0.15:\n",
        "                for param in optimizer.param_groups:\n",
        "                    param[\"lr\"]=1e-4\n",
        "\n",
        "    return train_loss_lst, val_loss_lst, batch_epoch_loss_lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rohT0_KNc2Hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss_lst, val_loss_lst, batch_epoch_loss_lst = train(epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL71ZxT7c2Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model=model, test_dl=train_dl, test_size=test_size):\n",
        "    test_loss = 0\n",
        "    for batch_idx,(batch_imgs,batch_labels) in enumerate(test_dl):\n",
        "        model.eval()\n",
        "        batch_imgs,batch_labels = batch_imgs.to(device),batch_labels.to(device)\n",
        "        output     = model(batch_imgs.float())\n",
        "        \n",
        "        # Reshape the outputs batch_size x 28 -> batch_size x 2 x 14\n",
        "        output     = output.view(batch_labels.shape)\n",
        "        loss       = criterion(output,batch_labels.float())\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        plt.figure()\n",
        "        plt.imshow(batch_imgs[0])\n",
        "        plt.scatter(202*(0.5 + np.transpose(output[0].detach().numpy())[:,0]), 202*(0.5 + np.transpose(output[0].detach().numpy())[:,1]),s=8,c=\"r\")\n",
        "        \n",
        "        break\n",
        "\n",
        "    return test_loss/test_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2qUZGr3c2Hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_2-8lkOc2Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2j2QPfqc2Hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}